# vLLM Engine

| Part                  | Core Concepts                                                                                          | Notes |
|-----------------------|--------------------------------------------------------------------------------------------------------|-------|
| LLM Engine & Core     | Scheduler, PagedAttention, KV-cache, CUDA Graphs                                                      |       |
| Advanced Features     | Chunked Prefill, Prefix Caching, Speculative Decoding, Guided Decoding, Disaggregated P/D              |       |
| Scaling Up            | MultiProcExecutor, Tensor Parallelism, Multi-GPU Scaling                                               |       |


## Acknowledgment

This projectâ€™s core vLLM system insights are based on "[Inside vLLM: Anatomy of a High-Throughput LLM Inference System](https://www.aleksagordic.com/blog/vllm)" by Aleksa Gordic.
